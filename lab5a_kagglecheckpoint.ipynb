{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":116343,"databundleVersionId":13883401,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n# The updated file paths reflecting the Kaggle input directory\nTRAIN_PATH = '/kaggle/input/dma-25-kaggle-competition/train.csv'\nTEST_PATH = '/kaggle/input/dma-25-kaggle-competition/test.csv'\nRANDOM_SEED = 42\n\n# 1. Load Data\ntrain_df = pd.read_csv(TRAIN_PATH)\ntest_df = pd.read_csv(TEST_PATH)\n\ntest_ids = test_df['PassengerId']\nfull_df = pd.concat([train_df.drop('Survived', axis=1), test_df], ignore_index=True)\n\n# 2. Feature Engineering and Preprocessing\nfull_df['Title'] = full_df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\nrare_titles = full_df['Title'].value_counts()[full_df['Title'].value_counts() < 10].index\nfull_df['Title'] = full_df['Title'].replace(rare_titles, 'Rare')\nfull_df['Title'] = full_df['Title'].replace(['Mme', 'Mlle', 'Ms'], 'Miss')\n\nfull_df['FamilySize'] = full_df['SibSp'] + full_df['Parch'] + 1\nfull_df['IsAlone'] = (full_df['FamilySize'] == 1).astype(int)\n\n# Impute Missing Values (using direct assignment)\nfull_df['Age'] = full_df['Age'].fillna(full_df['Age'].median())\nfull_df['Fare'] = full_df['Fare'].fillna(full_df['Fare'].median())\nfull_df['Embarked'] = full_df['Embarked'].fillna(full_df['Embarked'].mode()[0])\n\n# Drop non-essential columns\nfull_df = full_df.drop(['Name', 'Ticket', 'Cabin', 'SibSp', 'Parch', 'PassengerId'], axis=1)\n\n# 3. Encode Categorical Features\ncategorical_cols = ['Sex', 'Embarked', 'Pclass', 'Title']\nfull_df = pd.get_dummies(full_df, columns=categorical_cols, drop_first=True)\n\n# 4. Split Data\nX_train = full_df.iloc[:len(train_df)]\nX_test = full_df.iloc[len(train_df):]\ny_train = train_df['Survived']\n\n# 4b. Validation Split (For internal testing)\nX_train_model, X_val, y_train_model, y_val = train_test_split(\n    X_train, y_train, test_size=0.2, random_state=RANDOM_SEED\n)\n\n# 5. Model Training and Evaluation\nmodel = RandomForestClassifier(n_estimators=300, max_depth=11, min_samples_leaf=3, random_state=RANDOM_SEED)\nmodel.fit(X_train_model, y_train_model)\n\nval_predictions = model.predict(X_val)\nval_accuracy = accuracy_score(y_val, val_predictions)\nprint(f\"Validation Accuracy: {val_accuracy:.4f}\")\n\n# 6. Final Predictions and Submission\npredictions = model.predict(X_test)\n\nsubmission_df = pd.DataFrame({\n    'PassengerId': test_ids,\n    'Survived': predictions.astype(int)\n})\n\nprint(\"--- Submission Preview ---\")\nprint(submission_df.head())\nsubmission_df.to_csv('submission_data144_lab5a_t3.csv', index=False)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-04T21:36:45.281950Z","iopub.execute_input":"2025-10-04T21:36:45.282433Z","iopub.status.idle":"2025-10-04T21:36:45.861660Z","shell.execute_reply.started":"2025-10-04T21:36:45.282405Z","shell.execute_reply":"2025-10-04T21:36:45.860785Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/dma-25-kaggle-competition/train.csv\n/kaggle/input/dma-25-kaggle-competition/test.csv\n/kaggle/input/dma-25-kaggle-competition/gender_submission.csv\nValidation Accuracy: 0.8436\n--- Submission Preview ---\n   PassengerId  Survived\n0          892         0\n1          893         0\n2          894         0\n3          895         0\n4          896         1\n","output_type":"stream"}],"execution_count":21}]}